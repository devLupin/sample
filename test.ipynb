{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\worksrent\\anaconda3\\envs\\MMSegmentation\\lib\\site-packages\\mmcv\\__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
    "import mmcv\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.datasets.builder import DATASETS\n",
    "from mmseg.datasets.custom import CustomDataset\n",
    "\n",
    "classes = ('background', 'speech bubble')\n",
    "palette = [[0, 0, 0], [128, 128, 0]]\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class Dataset(CustomDataset):\n",
    "  CLASSES = classes\n",
    "  PALETTE = palette\n",
    "  def __init__(self, split, **kwargs):\n",
    "    super().__init__(img_suffix='.png', seg_map_suffix='.png', \n",
    "                     split=split, **kwargs)\n",
    "    assert osp.exists(self.img_dir) and self.split is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'configs/sem_fpn/fpn_r101_512x1024_80k_cityscapes.py '\n",
    "checkpoint_file = 'checkpoints/fpn_r101_512x1024_80k_cityscapes_20200717_012416-c5800d4c.pth'\n",
    "\n",
    "from mmcv import Config\n",
    "\n",
    "cfg = Config.fromfile(config_file)\n",
    "# print(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.norm_cfg = dict(type='SyncBN', requires_grad=True)\n",
    "cfg.model = dict(\n",
    "    type='EncoderDecoder',\n",
    "    pretrained='open-mmlab://resnet101_v1c',\n",
    "    backbone=dict(\n",
    "        type='ResNetV1c',\n",
    "        depth=101,\n",
    "        num_stages=4,\n",
    "        out_indices=(0, 1, 2, 3),\n",
    "        dilations=(1, 1, 1, 1),\n",
    "        strides=(1, 2, 2, 2),\n",
    "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
    "        norm_eval=False,\n",
    "        style='pytorch',\n",
    "        contract_dilation=True),\n",
    "    neck=dict(\n",
    "        type='FPN',\n",
    "        in_channels=[256, 512, 1024, 2048],\n",
    "        out_channels=256,\n",
    "        num_outs=4),\n",
    "    decode_head=dict(\n",
    "        type='FPNHead',\n",
    "        in_channels=[256, 256, 256, 256],\n",
    "        in_index=[0, 1, 2, 3],\n",
    "        feature_strides=[4, 8, 16, 32],\n",
    "        channels=128,\n",
    "        dropout_ratio=0.1,\n",
    "        num_classes=2,\n",
    "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
    "        align_corners=False,\n",
    "        loss_decode=dict(\n",
    "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n",
    "    train_cfg=dict(),\n",
    "    test_cfg=dict(mode='whole'))\n",
    "cfg.dataset_type = 'Dataset'\n",
    "cfg.data_root = 'datasets'\n",
    "cfg.img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "cfg.crop_size = (720, 720)\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='Resize', img_scale=(720, 720), ratio_range=(0.5, 2.0)),\n",
    "    dict(type='RandomCrop', crop_size=(720, 720), cat_max_ratio=0.75),\n",
    "    # dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    # dict(type='PhotoMetricDistortion'),\n",
    "    dict(\n",
    "        type='Normalize',\n",
    "        mean=[123.675, 116.28, 103.53],\n",
    "        std=[58.395, 57.12, 57.375],\n",
    "        to_rgb=True),\n",
    "    # dict(type='Pad', size=(512, 1024), pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
    "]\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(720, 720),\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='RandomFlip'),\n",
    "            dict(\n",
    "                type='Normalize',\n",
    "                mean=[123.675, 116.28, 103.53],\n",
    "                std=[58.395, 57.12, 57.375],\n",
    "                to_rgb=True),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img'])\n",
    "        ])\n",
    "]\n",
    "cfg.data = dict(\n",
    "    samples_per_gpu=8,\n",
    "    workers_per_gpu=8,\n",
    "    train=dict(\n",
    "        type='Dataset',\n",
    "        data_root='datasets',\n",
    "        img_dir='images',\n",
    "        ann_dir='labels',\n",
    "        pipeline=[\n",
    "            dict(type='LoadImageFromFile'),\n",
    "            dict(type='LoadAnnotations'),\n",
    "            dict(\n",
    "                type='Resize', img_scale=(720, 720), ratio_range=(0.5, 2.0)),\n",
    "            dict(type='RandomCrop', crop_size=(720, 720), cat_max_ratio=0.75),\n",
    "            # dict(type='RandomFlip', flip_ratio=0.5),\n",
    "            # dict(type='PhotoMetricDistortion'),\n",
    "            dict(\n",
    "                type='Normalize',\n",
    "                mean=[123.675, 116.28, 103.53],\n",
    "                std=[58.395, 57.12, 57.375],\n",
    "                to_rgb=True),\n",
    "            # dict(type='Pad', size=(512, 1024), pad_val=0, seg_pad_val=255),\n",
    "            dict(type='DefaultFormatBundle'),\n",
    "            dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
    "        ],\n",
    "        split='splits/train.txt'),\n",
    "    val=dict(\n",
    "        type='Dataset',\n",
    "        data_root='datasets',\n",
    "        img_dir='images',\n",
    "        ann_dir='labels',\n",
    "        pipeline=[\n",
    "            dict(type='LoadImageFromFile'),\n",
    "            dict(\n",
    "                type='MultiScaleFlipAug',\n",
    "                img_scale=(720, 720),\n",
    "                flip=False,\n",
    "                transforms=[\n",
    "                    dict(type='Resize', keep_ratio=True),\n",
    "                    # dict(type='RandomFlip'),\n",
    "                    dict(\n",
    "                        type='Normalize',\n",
    "                        mean=[123.675, 116.28, 103.53],\n",
    "                        std=[58.395, 57.12, 57.375],\n",
    "                        to_rgb=True),\n",
    "                    dict(type='ImageToTensor', keys=['img']),\n",
    "                    dict(type='Collect', keys=['img'])\n",
    "                ])\n",
    "        ],\n",
    "        split='splits/val.txt'),\n",
    "    test=dict(\n",
    "        type='Dataset',\n",
    "        data_root='datasets',\n",
    "        img_dir='images',\n",
    "        ann_dir='labels',\n",
    "        pipeline=[\n",
    "            dict(type='LoadImageFromFile'),\n",
    "            dict(\n",
    "                type='MultiScaleFlipAug',\n",
    "                img_scale=(720, 720),\n",
    "                flip=False,\n",
    "                transforms=[\n",
    "                    dict(type='Resize', keep_ratio=True),\n",
    "                    # dict(type='RandomFlip'),\n",
    "                    dict(\n",
    "                        type='Normalize',\n",
    "                        mean=[123.675, 116.28, 103.53],\n",
    "                        std=[58.395, 57.12, 57.375],\n",
    "                        to_rgb=True),\n",
    "                    dict(type='ImageToTensor', keys=['img']),\n",
    "                    dict(type='Collect', keys=['img'])\n",
    "                ])\n",
    "        ],\n",
    "        split='splits/val.txt'))\n",
    "cfg.log_config = dict(\n",
    "    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\n",
    "cfg.dist_params = dict(backend='nccl')\n",
    "cfg.log_level = 'INFO'\n",
    "cfg.load_from = 'checkpoints/fpn_r101_512x1024_80k_cityscapes_20200717_012416-c5800d4c.pth'\n",
    "cfg.resume_from = None\n",
    "cfg.workflow = [('train', 1)]\n",
    "cfg.cudnn_benchmark = True\n",
    "cfg.optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "cfg.optimizer_config = dict()\n",
    "cfg.lr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)\n",
    "cfg.runner = dict(type='IterBasedRunner', max_iters=4000)\n",
    "cfg.checkpoint_config = dict(by_epoch=False, interval=1000)\n",
    "cfg.evaluation = dict(interval=1000, metric='mIoU', pre_eval=True)\n",
    "cfg.work_dir = 'datasets'\n",
    "cfg.seed = 0\n",
    "cfg.gpu_ids = range(0, 2)\n",
    "cfg.device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 16:03:20,142 - mmseg - INFO - Loaded 13840 images\n",
      "d:\\dev\\mmsegmentation\\mmseg\\models\\backbones\\resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
      "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n",
      "d:\\dev\\mmsegmentation\\mmseg\\models\\decode_heads\\decode_head.py:94: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert seg_logist into a predictionapplying a threshold\n",
      "  warnings.warn('For binary segmentation, we suggest using'\n",
      "d:\\dev\\mmsegmentation\\mmseg\\models\\losses\\cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('background', 'speech bubble')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 16:03:20,958 - mmseg - INFO - Loaded 3460 images\n",
      "2022-11-29 16:03:20,958 - mmseg - INFO - load checkpoint from local path: checkpoints/fpn_r101_512x1024_80k_cityscapes_20200717_012416-c5800d4c.pth\n",
      "2022-11-29 16:03:21,255 - mmseg - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for decode_head.conv_seg.weight: copying a param with shape torch.Size([19, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 128, 1, 1]).\n",
      "size mismatch for decode_head.conv_seg.bias: copying a param with shape torch.Size([19]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "2022-11-29 16:03:21,295 - mmseg - INFO - Start running, host: worksrent@2UA75126TD, work_dir: d:\\dev\\mmsegmentation\\datasets\n",
      "2022-11-29 16:03:21,297 - mmseg - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-11-29 16:03:21,298 - mmseg - INFO - workflow: [('train', 1)], max: 4000 iters\n",
      "2022-11-29 16:03:21,300 - mmseg - INFO - Checkpoints will be saved to d:\\dev\\mmsegmentation\\datasets by HardDiskBackend.\n"
     ]
    }
   ],
   "source": [
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import train_segmentor\n",
    "from torchinfo import summary\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the detector\n",
    "model = build_segmentor(\n",
    "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "\n",
    "# print(model, (32, 1, 720, 720))\n",
    "\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "print(datasets[0].CLASSES)\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_segmentor(model, datasets, cfg, distributed=False, validate=True, \n",
    "                meta=dict(CLASSES=classes, PALETTE=palette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('MMSegmentation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61f6bbef98ad3319236a669d2c1383bc3118887be8875ac8bd4e7de25af53a5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
